{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Real-Time Inferencing Service with AKS\n",
    "\n",
    "This is very similar to deploying to ACI, but we want to use an AKS inferencing cluster which will allow us to have more control and scale.  \n",
    "\n",
    "I'll point out the specific differences, otherwise the code can be considered to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.27.0 to work with mlops\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Model\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder for the experiment files used\n",
    "training_folder = 'driver-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_model version 3\n"
     ]
    }
   ],
   "source": [
    "# Get the latest registered version of the model\n",
    "model = ws.models['driver_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/davew202105/code/git/MLOps-E2E-sdkv2/Lab12\n"
     ]
    }
   ],
   "source": [
    "# you need to figure out where you want to put the service folder\n",
    "# ideally this should be at the same level as the driver-training folder\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will recycle the same inferencing code, so service_path should already exist and work\n",
    "# we won't rebuild those files.  \n",
    "import os\n",
    "\n",
    "# changeme\n",
    "service_path = 'inf-svc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_env.yml\tscore.py\n"
     ]
    }
   ],
   "source": [
    "# we should have score.py and driver_env.yml in this folder\n",
    "# we will use those next\n",
    "!ls $service_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/Attach to AKS AMLS Compute Target\n",
    "\n",
    "We want to create or attach to the AMLS inferencing cluster.  Mine is called `infer-cluster`, but you can call it whatever you want.  Your team can share an inferencing cluster but the service names will need to be unique for each team member.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found existing compute target.\n",
      "Aml Compute attached\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = 'infer-cluster'\n",
    "\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 1)    \n",
    "    aml_compute = ComputeTarget.create(ws, args.aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Aml Compute attached\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring/Inferencing Configuration\n",
    "\n",
    "* Now we need to configure the scoring environment.  \n",
    "* You can view the status of the deployment in the AMLS portal under `Endpoints`.  \n",
    "* the first deployment always takes a little while.  \n",
    "\n",
    "We are going to deploy to AKS such that if the webservice exists it will \"drop and recreate\".  This may not always be what you want to do.  You have options.\n",
    "\n",
    "Deployment will take some time as it first runs a process to create a container image, and then runs a process to create a web service based on the image. When deployment has completed successfully, you'll see a status of **Healthy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-01 16:15:36+00:00 Creating Container Registry if not exists.\n",
      "2021-06-01 16:15:37+00:00 Registering the environment.\n",
      "2021-06-01 16:15:38+00:00 Use the existing image.\n",
      "2021-06-01 16:15:41+00:00 Creating resources in AKS..\n",
      "2021-06-01 16:15:41+00:00 Submitting deployment to compute.\n",
      "2021-06-01 16:15:42+00:00 Checking the status of deployment driver-service-sdk2-aks..\n",
      "2021-06-01 16:17:25+00:00 Checking the status of inference endpoint driver-service-sdk2-aks.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2021-06-01T16:17:14,437054043+00:00 - iot-server/run \n",
      "2021-06-01T16:17:14,438284041+00:00 - rsyslog/run \n",
      "2021-06-01T16:17:14,439061304+00:00 - gunicorn/run \n",
      "2021-06-01T16:17:14,448339048+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_deade6e796a908fdec1522cb257b3da0/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_deade6e796a908fdec1522cb257b3da0/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_deade6e796a908fdec1522cb257b3da0/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_deade6e796a908fdec1522cb257b3da0/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_deade6e796a908fdec1522cb257b3da0/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-01T16:17:14,521529620+00:00 - iot-server/finish 1 0\n",
      "2021-06-01T16:17:14,522934132+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-06-01 16:17:15,598 | root | INFO | Starting up app insights client\n",
      "2021-06-01 16:17:15,598 | root | INFO | Starting up request id generator\n",
      "2021-06-01 16:17:15,598 | root | INFO | Starting up app insight hooks\n",
      "2021-06-01 16:17:15,598 | root | INFO | Invoking user's init function\n",
      "2021-06-01 16:17:16,144 | root | INFO | Users's init has completed successfully\n",
      "2021-06-01 16:17:16,147 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-06-01 16:17:16,147 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-06-01 16:17:16,148 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-06-01 16:17:25,703 | root | INFO | Swagger file not present\n",
      "2021-06-01 16:17:25,704 | root | INFO | 404\n",
      "127.0.0.1 - - [01/Jun/2021:16:17:25 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.17.4\"\n",
      "2021-06-01 16:17:26,065 | root | INFO | Swagger file not present\n",
      "2021-06-01 16:17:26,065 | root | INFO | 404\n",
      "127.0.0.1 - - [01/Jun/2021:16:17:26 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2021-06-01 16:17:32,962 | root | INFO | Swagger file not present\n",
      "2021-06-01 16:17:32,962 | root | INFO | 404\n",
      "127.0.0.1 - - [01/Jun/2021:16:17:32 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.17.4\"\n",
      "2021-06-01 16:17:33,756 | root | INFO | Swagger file not present\n",
      "2021-06-01 16:17:33,757 | root | INFO | 404\n",
      "127.0.0.1 - - [01/Jun/2021:16:17:33 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "service_name = \"driver-service-sdk2-aks\"\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = service_path,\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"driver_env.yml\")\n",
    "\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, aml_compute)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, the deployment has been successful and you can see a status of **Healthy**. If not, you can use the following code to check the status and get the service logs to help you troubleshoot.\n",
    "\n",
    "Take a look at your workspace in [Azure ML Studio](https://ml.azure.com) and view the **Endpoints** page, which shows the deployed services in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you need to make a change and redeploy you may need to delete the old, unhealthy service.  Use the following code:\n",
    "# service.delete()\n",
    "# but don't delete the service yet after you get a good deployment.  We will use test the service next.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver-service-sdk2-aks\n",
      "driver-service-sdk2\n",
      "driver-service\n",
      "bikebuyeraciws\n",
      "ar-factoring-2class\n",
      "predict-attrition-svc1\n",
      "support-ticket-duration\n",
      "bikebuyer2-aks-service\n",
      "bikebuyer-aci\n",
      "compliance-classifier-service\n",
      "bb-aks-service\n"
     ]
    }
   ],
   "source": [
    "# print the webservice endpoints\n",
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Web Service\n",
    "\n",
    "With the service deployed, now you can consume it from a client application.  \n",
    "Using AKS requires REST requests to include an **Authorization** header.  Let's do all of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://104.41.151.19:80/api/v1/service/driver-service-sdk2-aks/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"result\": [0.027311045841034335, 0.0261231327307869]}'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data = {\"data\":\n",
    "    [\n",
    "        [0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],\n",
    "        [4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]\n",
    "    ]\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "api_key = '4LBGhoC7fHRd7DLvIowFgP58mfwzbEtv' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(endpoint, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Service\n",
    "\n",
    "When you no longer need your service, you should delete it to avoid incurring unecessary charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about publishing a model as a service, see the [documentation](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
