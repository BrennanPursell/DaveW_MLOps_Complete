{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the same basic algorithm and process, but now we are going to inject the AMLS scaffolding so we can do model training at scale.  \n",
    "## Set up the experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import urllib.request\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'driver-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# refresh the left hand folder pane to see the new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('driver-training/training_data.csv',\n",
       " <http.client.HTTPMessage at 0x7fc4030488d0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the data file into the experiment folder\n",
    "training_data = \"https://davewdemoblobs.blob.core.windows.net/oh-datascience/porto_seguro_safe_driver_prediction_input_train.csv?sv=2019-12-12&st=2020-01-11T20%3A35%3A00Z&se=2025-01-12T20%3A35%3A00Z&sr=b&sp=r&sig=aD%2F9WIK4cTutqt0I02XquzP1ncDipHdz356omvKdMUI%3D\"\n",
    "urllib.request.urlretrieve (training_data, os.path.join(training_folder,\"training_data.csv\"))\n",
    "\n",
    "# make sure your training data is in the experiment folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py\n",
    "This file defines the key functions required to train the model.  \n",
    "The file can be invoked with `python train.py` for development purposes.\n",
    "\n",
    "This is basically the same code as before but we've done some \"tricks\" with it, documented inline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver-training/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/train.py\n",
    "# the above code says \"don't execute this cell, instead, write the cell out to the filesystem\".  This\n",
    "# is a trick to building a train.py from a jupyter notebook, but not necessarily the only way.  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm\n",
    "\n",
    "# we've created a set of helper functions to make the code more readable when we make changes later.  \n",
    "def split_data(data_df):\n",
    "    \"\"\"Split a dataframe into training and validation datasets\"\"\"\n",
    "    features = data_df.drop(['target', 'id'], axis=1)\n",
    "    labels = np.array(data_df['target'])\n",
    "    (features_train,\n",
    "     features_valid,\n",
    "     labels_train,\n",
    "     labels_valid) = train_test_split(\n",
    "         features,\n",
    "         labels,\n",
    "         test_size=0.2,\n",
    "         random_state=0)\n",
    "\n",
    "    train_data = lightgbm.Dataset(\n",
    "        features_train,\n",
    "        label=labels_train)\n",
    "    valid_data = lightgbm.Dataset(\n",
    "        features_valid,\n",
    "        label=labels_valid,\n",
    "        free_raw_data=False)\n",
    "    return (train_data, valid_data)\n",
    "\n",
    "\n",
    "def train_model(data, parameters):\n",
    "    \"\"\"Train a model with the given datasets and parameters\"\"\"\n",
    "    # The data returned in split_data is an array.\n",
    "    # Access train_data with data[0] and valid_data with data[1]\n",
    "    model = lightgbm.train(parameters,\n",
    "                           data[0],\n",
    "                           valid_sets=data[1],\n",
    "                           num_boost_round=500,\n",
    "                           early_stopping_rounds=20)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_metrics(model, data):\n",
    "    \"\"\"Construct a dictionary of metrics for the model\"\"\"\n",
    "    predictions = model.predict(data[1].data)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(data[1].label, predictions)\n",
    "    model_metrics = {\"auc\": (metrics.auc(fpr, tpr))}\n",
    "    return model_metrics\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"This method invokes the training functions for development purposes\"\"\"\n",
    "\n",
    "    # Read data from a file\n",
    "    data_df = pd.read_csv('training_data.csv')\n",
    "\n",
    "    # Hard code the parameters for training the model\n",
    "    parameters = {\n",
    "        'learning_rate': 0.02,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'sub_feature': 0.7,\n",
    "        'num_leaves': 60,\n",
    "        'min_data': 100,\n",
    "        'min_hessian': 1,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Invoke the functions defined in this file\n",
    "    data = split_data(data_df)\n",
    "    model = train_model(data, parameters)\n",
    "    metrics = get_model_metrics(model, data)\n",
    "\n",
    "    # Print the resulting metrics for the model\n",
    "    print(metrics)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure `train.py` was written to the experiment folder\n",
    "\n",
    "## parameters.json\n",
    "This file will specify the parameters used to train the model. \n",
    "\n",
    "Again, note we are not executing this cell, we are writing it to our experiment folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver-training/parameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/parameters.json\n",
    "{\n",
    "    \"training\":\n",
    "    {\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"sub_feature\": 0.7,\n",
    "        \"num_leaves\": 60,\n",
    "        \"min_data\": 100,\n",
    "        \"min_hessian\": 1,\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driver_training.py\n",
    "This file will be the entry script when running an Azure ML context.  \n",
    "It calls the functions defined in train.py for data preparation and training, but reads parameters from a file, and logs output to the Azure ML context.  \n",
    "The file can be invoked with `python driver_training.py` for development purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver-training/driver_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/driver_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import functions from train.py\n",
    "from train import split_data, train_model, get_model_metrics\n",
    "\n",
    "# Get the output folder for the model from the '--output_folder' parameter\n",
    "# Specify a default value for this parameter as 'outputs'\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', \n",
    "                    type=str, \n",
    "                    dest='output_folder',\n",
    "                    default=\"outputs\")\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the dataset\n",
    "train_df = pd.read_csv('training_data.csv')\n",
    "\n",
    "# Load the parameters for training the model from the file\n",
    "with open(\"parameters.json\") as f:\n",
    "    pars = json.load(f)\n",
    "    parameters = pars[\"training\"]\n",
    "\n",
    "# Log the parameters\n",
    "for k, v in parameters.items():\n",
    "    run.log(k, v)\n",
    "\n",
    "data = split_data(train_df)\n",
    "model = train_model(data, parameters)\n",
    "metrics = get_model_metrics(model, data)\n",
    "\n",
    "# Log metrics\n",
    "for k, v in metrics.items():\n",
    "    run.log(k, v)\n",
    "\n",
    "# Save the trained model to the output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/driver_model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code RLPHUBGGA to authenticate.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Failed to authenticate to tenant '354e6dce-302d-4d66-9ae3-8947df67c030' due to error 'Get Token request returned http error: 400 and server response: {\"error\":\"interaction_required\",\"error_description\":\"AADSTS50076: Due to a configuration change made by your administrator, or because you moved to a new location, you must use multi-factor authentication to access '797f4846-ba00-4fd7-ba43-dac1f8f63013'.\\r\\nTrace ID: 0494e4b5-82a4-4080-b961-321b980c2c00\\r\\nCorrelation ID: f69bd19b-a2f8-423c-9b56-07db2ff6d9c5\\r\\nTimestamp: 2021-03-08 16:15:41Z\",\"error_codes\":[50076],\"timestamp\":\"2021-03-08 16:15:41Z\",\"trace_id\":\"0494e4b5-82a4-4080-b961-321b980c2c00\",\"correlation_id\":\"f69bd19b-a2f8-423c-9b56-07db2ff6d9c5\",\"error_uri\":\"https://login.microsoftonline.com/error?code=50076\",\"suberror\":\"basic_action\"}'.Will continue to look for other tenants to find subscriptions to which you have access\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace, if you are running this from an AMLS compute the config will already be created.\n",
    "# Otherwise you'll need to build a config file.  I can help you with this but the documentation is also elsewhere\n",
    "# in this repo\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an Estimator to Run the Script as an Experiment\n",
    "\n",
    "See [this tutorial](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/02-Training_Models.ipynb) for a starting point\n",
    "\n",
    "Use the scikit-learn and lightgbm conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: driver-training_1615220307_73384b5a\n",
      "Web View: https://ml.azure.com/experiments/driver-training/runs/driver-training_1615220307_73384b5a?wsid=/subscriptions/52061d21-01dd-4f9e-aca9-60fff4d67ee2/resourcegroups/MLOpsWorkshop/workspaces/mlops\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "[2021-03-08T16:18:35.442536] Entering context manager injector.\n",
      "Cannot provide tracer without any exporter configured.\n",
      "[2021-03-08T16:18:36.272529] Using urllib.request Python 3.0 or later\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 15923\n",
      "Running: ['/bin/bash', '/tmp/azureml_runs/driver-training_1615220307_73384b5a/azureml-environment-setup/docker_env_checker.sh']\n",
      "\n",
      "Materialized image not found on target: azureml/azureml_ca5cde6fc63b668f23d793c46084bb15\n",
      "\n",
      "\n",
      "[2021-03-08T16:18:39.643568] Logging experiment preparation status in history service.\n",
      "Running: ['/bin/bash', '/tmp/azureml_runs/driver-training_1615220307_73384b5a/azureml-environment-setup/docker_env_builder.sh']\n",
      "Running: ['nvidia-docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '-t', 'azureml/azureml_ca5cde6fc63b668f23d793c46084bb15', '.']\n",
      "Sending build context to Docker daemon  116.5MB\n",
      "Step 1/14 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "8e097b52bfb8: Pulling fs layer\n",
      "a613a9b4553c: Pulling fs layer\n",
      "acc000f01536: Pulling fs layer\n",
      "73eef93b7466: Pulling fs layer\n",
      "d5a54c1fb97f: Pulling fs layer\n",
      "1536f6ca931b: Pulling fs layer\n",
      "d7b631d130cb: Pulling fs layer\n",
      "75ffe8dfb222: Pulling fs layer\n",
      "86b4bf2f8d5f: Pulling fs layer\n",
      "5335952fa8d3: Pulling fs layer\n",
      "96fa3cc6fe10: Pulling fs layer\n",
      "e428dd9daa94: Pulling fs layer\n",
      "1536f6ca931b: Waiting\n",
      "d7b631d130cb: Waiting\n",
      "75ffe8dfb222: Waiting\n",
      "86b4bf2f8d5f: Waiting\n",
      "5335952fa8d3: Waiting\n",
      "96fa3cc6fe10: Waiting\n",
      "e428dd9daa94: Waiting\n",
      "d5a54c1fb97f: Waiting\n",
      "73eef93b7466: Waiting\n",
      "a613a9b4553c: Verifying Checksum\n",
      "a613a9b4553c: Download complete\n",
      "acc000f01536: Download complete\n",
      "73eef93b7466: Verifying Checksum\n",
      "73eef93b7466: Download complete\n",
      "d5a54c1fb97f: Verifying Checksum\n",
      "d5a54c1fb97f: Download complete\n",
      "1536f6ca931b: Verifying Checksum\n",
      "1536f6ca931b: Download complete\n",
      "8e097b52bfb8: Verifying Checksum\n",
      "8e097b52bfb8: Download complete\n",
      "d7b631d130cb: Verifying Checksum\n",
      "d7b631d130cb: Download complete\n",
      "75ffe8dfb222: Verifying Checksum\n",
      "75ffe8dfb222: Download complete\n",
      "96fa3cc6fe10: Verifying Checksum\n",
      "96fa3cc6fe10: Download complete\n",
      "e428dd9daa94: Download complete\n",
      "5335952fa8d3: Verifying Checksum\n",
      "5335952fa8d3: Download complete\n",
      "8e097b52bfb8: Pull complete\n",
      "a613a9b4553c: Pull complete\n",
      "acc000f01536: Pull complete\n",
      "86b4bf2f8d5f: Verifying Checksum\n",
      "86b4bf2f8d5f: Download complete\n",
      "73eef93b7466: Pull complete\n",
      "d5a54c1fb97f: Pull complete\n",
      "1536f6ca931b: Pull complete\n",
      "d7b631d130cb: Pull complete\n",
      "75ffe8dfb222: Pull complete\n",
      "86b4bf2f8d5f: Pull complete\n",
      "5335952fa8d3: Pull complete\n",
      "96fa3cc6fe10: Pull complete\n",
      "e428dd9daa94: Pull complete\n",
      "Digest: sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1@sha256:8cee6f674276dddb23068d2710da7f7f95b119412cc482675ac79ba45a4acf99\n",
      " ---> 287916b809d9\n",
      "Step 2/14 : USER root\n",
      " ---> Running in 66a39c1c6b82\n",
      "Removing intermediate container 66a39c1c6b82\n",
      " ---> 752c181205b5\n",
      "Step 3/14 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 6a04afe7f3e9\n",
      "Removing intermediate container 6a04afe7f3e9\n",
      " ---> aed81d2b261e\n",
      "Step 4/14 : WORKDIR /\n",
      " ---> Running in 52cecbb80595\n",
      "Removing intermediate container 52cecbb80595\n",
      " ---> 0f0e7bd10470\n",
      "Step 5/14 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 55be8144dd6e\n",
      "Step 6/14 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 0b320cde67b7\n",
      "Removing intermediate container 0b320cde67b7\n",
      " ---> 2815f03362b6\n",
      "Step 7/14 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> b6130ea8e0e3\n",
      "Step 8/14 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in c4ecdadc6ca2\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "lightgbm-2.3.0       | 1.0 MB    | ########## | 100% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.m4gkowr6.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.23.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.23.0\n",
      "  Downloading azureml_dataset_runtime-1.23.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting azureml-core~=1.23.0\n",
      "  Downloading azureml_core-1.23.0-py3-none-any.whl (2.1 MB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.m4gkowr6.requirements.txt (line 1)) (1.15.0)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.6-py2.py3-none-any.whl (55 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.0 in /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.m4gkowr6.requirements.txt (line 1)) (1.19.1)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting azureml-dataprep<2.11.0a,>=2.10.0a\n",
      "  Downloading azureml_dataprep-2.10.1-py3-none-any.whl (39.4 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.26-py2.py3-none-any.whl (12 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<=3.2\n",
      "  Downloading cryptography-3.2-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.m4gkowr6.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting azureml-dataprep-rslex<1.9.0a,>=1.8.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.8.1-cp36-cp36m-manylinux1_x86_64.whl (9.0 MB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-native<31.0.0,>=30.0.0\n",
      "  Downloading azureml_dataprep_native-30.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (32 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.9.0-py2.py3-none-any.whl (59 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.11.0-py2.py3-none-any.whl (127 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: json-logging-py, liac-arff, fusepy\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=40f6d68a7416886df283738c129f0b2d8fdc76ac449be67606514c68bb2fdd02\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=e66af39054e4b073d77c1972e3e2b7a7f1a73adb585298797b0c8d80ccd53522\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=dc2d3f1f82f5bd57e08905a92667d1ffb74c549a402bf0fc92184cf9884715c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built json-logging-py liac-arff fusepy\n",
      "Installing collected packages: werkzeug, applicationinsights, gunicorn, liac-arff, chardet, urllib3, idna, requests, python-dateutil, PyJWT, pycparser, cffi, cryptography, adal, dill, pytz, pandas, azureml-model-management-sdk, configparser, json-logging-py, pyarrow, distro, dotnetcore2, cloudpickle, azureml-dataprep-rslex, portalocker, msal, msal-extensions, azure-core, azure-identity, azureml-dataprep-native, azureml-dataprep, fusepy, azureml-dataset-runtime, pathspec, pyasn1, pyopenssl, ndg-httpsclient, azure-common, contextlib2, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, azure-graphrbac, zipp, typing-extensions, importlib-metadata, jsonpickle, azure-mgmt-resource, backports.weakref, backports.tempfile, azure-mgmt-keyvault, jmespath, websocket-client, docker, azure-mgmt-storage, jeepney, SecretStorage, azure-mgmt-authorization, azure-mgmt-containerregistry, ruamel.yaml.clib, ruamel.yaml, azureml-core, itsdangerous, click, MarkupSafe, Jinja2, flask, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 SecretStorage-3.3.1 adal-1.2.6 applicationinsights-0.11.9 azure-common-1.1.26 azure-core-1.11.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.23.0 azureml-dataprep-2.10.1 azureml-dataprep-native-30.0.0 azureml-dataprep-rslex-1.8.1 azureml-dataset-runtime-1.23.0 azureml-defaults-1.23.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.2 dill-0.3.3 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-3.7.2 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.9.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pandas-1.1.5 pathspec-0.8.1 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.16.13 ruamel.yaml.clib-0.2.2 typing-extensions-3.7.4.3 urllib3-1.26.3 websocket-client-0.58.0 werkzeug-1.0.1 zipp-3.4.1\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "[2021-03-08T16:22:43.751907] Entering context manager injector.\n",
      "Cannot provide tracer without any exporter configured.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver_training.py'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 9\n",
      "[2021-03-08T16:22:44.757216] Entering Run History Context Manager.\n",
      "[2021-03-08T16:22:45.649765] Current directory: /azureml-run\n",
      "[2021-03-08T16:22:45.649809] Preparing to call script [driver_training.py] with arguments:[]\n",
      "[2021-03-08T16:22:45.649827] After variable expansion, calling script [driver_training.py] with arguments:[]\n",
      "\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[1]\tvalid_0's auc: 0.595844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.605252\n",
      "[3]\tvalid_0's auc: 0.612784\n",
      "[4]\tvalid_0's auc: 0.61756\n",
      "[5]\tvalid_0's auc: 0.620129\n",
      "[6]\tvalid_0's auc: 0.622447\n",
      "[7]\tvalid_0's auc: 0.622163\n",
      "[8]\tvalid_0's auc: 0.622112\n",
      "[9]\tvalid_0's auc: 0.622581\n",
      "[10]\tvalid_0's auc: 0.622278\n",
      "[11]\tvalid_0's auc: 0.622433\n",
      "[12]\tvalid_0's auc: 0.623423\n",
      "[13]\tvalid_0's auc: 0.623618\n",
      "[14]\tvalid_0's auc: 0.62414\n",
      "[15]\tvalid_0's auc: 0.624421\n",
      "[16]\tvalid_0's auc: 0.624512\n",
      "[17]\tvalid_0's auc: 0.625151\n",
      "[18]\tvalid_0's auc: 0.62529\n",
      "[19]\tvalid_0's auc: 0.625437\n",
      "[20]\tvalid_0's auc: 0.62563\n",
      "[21]\tvalid_0's auc: 0.625963\n",
      "[22]\tvalid_0's auc: 0.626147\n",
      "[23]\tvalid_0's auc: 0.626383\n",
      "[24]\tvalid_0's auc: 0.626618\n",
      "[25]\tvalid_0's auc: 0.626586\n",
      "[26]\tvalid_0's auc: 0.626839\n",
      "[27]\tvalid_0's auc: 0.626972\n",
      "[28]\tvalid_0's auc: 0.626935\n",
      "[29]\tvalid_0's auc: 0.626946\n",
      "[30]\tvalid_0's auc: 0.627204\n",
      "[31]\tvalid_0's auc: 0.627252\n",
      "[32]\tvalid_0's auc: 0.627302\n",
      "[33]\tvalid_0's auc: 0.627249\n",
      "[34]\tvalid_0's auc: 0.627517\n",
      "[35]\tvalid_0's auc: 0.627755\n",
      "[36]\tvalid_0's auc: 0.62766\n",
      "[37]\tvalid_0's auc: 0.627483\n",
      "[38]\tvalid_0's auc: 0.627578\n",
      "[39]\tvalid_0's auc: 0.627433\n",
      "[40]\tvalid_0's auc: 0.627573\n",
      "[41]\tvalid_0's auc: 0.627908\n",
      "[42]\tvalid_0's auc: 0.627968\n",
      "[43]\tvalid_0's auc: 0.628082\n",
      "[44]\tvalid_0's auc: 0.628398\n",
      "[45]\tvalid_0's auc: 0.628763\n",
      "[46]\tvalid_0's auc: 0.629011\n",
      "[47]\tvalid_0's auc: 0.629321\n",
      "[48]\tvalid_0's auc: 0.629341\n",
      "[49]\tvalid_0's auc: 0.629353\n",
      "[50]\tvalid_0's auc: 0.629291\n",
      "[51]\tvalid_0's auc: 0.629447\n",
      "[52]\tvalid_0's auc: 0.629507\n",
      "[53]\tvalid_0's auc: 0.629725\n",
      "[54]\tvalid_0's auc: 0.630048\n",
      "[55]\tvalid_0's auc: 0.630085\n",
      "[56]\tvalid_0's auc: 0.630035\n",
      "[57]\tvalid_0's auc: 0.630236\n",
      "[58]\tvalid_0's auc: 0.630486\n",
      "[59]\tvalid_0's auc: 0.630663\n",
      "[60]\tvalid_0's auc: 0.630787\n",
      "[61]\tvalid_0's auc: 0.630932\n",
      "[62]\tvalid_0's auc: 0.631004\n",
      "[63]\tvalid_0's auc: 0.631161\n",
      "[64]\tvalid_0's auc: 0.631407\n",
      "[65]\tvalid_0's auc: 0.631408\n",
      "[66]\tvalid_0's auc: 0.631515\n",
      "[67]\tvalid_0's auc: 0.631631\n",
      "[68]\tvalid_0's auc: 0.631628\n",
      "[69]\tvalid_0's auc: 0.631703\n",
      "[70]\tvalid_0's auc: 0.631781\n",
      "[71]\tvalid_0's auc: 0.631786\n",
      "[72]\tvalid_0's auc: 0.631779\n",
      "[73]\tvalid_0's auc: 0.632022\n",
      "[74]\tvalid_0's auc: 0.632086\n",
      "[75]\tvalid_0's auc: 0.632107\n",
      "[76]\tvalid_0's auc: 0.632201\n",
      "[77]\tvalid_0's auc: 0.632165\n",
      "[78]\tvalid_0's auc: 0.632335\n",
      "[79]\tvalid_0's auc: 0.632446\n",
      "[80]\tvalid_0's auc: 0.63254\n",
      "[81]\tvalid_0's auc: 0.632654\n",
      "[82]\tvalid_0's auc: 0.632663\n",
      "[83]\tvalid_0's auc: 0.632811\n",
      "[84]\tvalid_0's auc: 0.63291\n",
      "[85]\tvalid_0's auc: 0.632993\n",
      "[86]\tvalid_0's auc: 0.632962\n",
      "[87]\tvalid_0's auc: 0.632941\n",
      "[88]\tvalid_0's auc: 0.633062\n",
      "[89]\tvalid_0's auc: 0.633144\n",
      "[90]\tvalid_0's auc: 0.633242\n",
      "[91]\tvalid_0's auc: 0.633336\n",
      "[92]\tvalid_0's auc: 0.633453\n",
      "[93]\tvalid_0's auc: 0.633556\n",
      "[94]\tvalid_0's auc: 0.633648\n",
      "[95]\tvalid_0's auc: 0.633762\n",
      "[96]\tvalid_0's auc: 0.633831\n",
      "[97]\tvalid_0's auc: 0.633922\n",
      "[98]\tvalid_0's auc: 0.633908\n",
      "[99]\tvalid_0's auc: 0.633958\n",
      "[100]\tvalid_0's auc: 0.634122\n",
      "[101]\tvalid_0's auc: 0.634278\n",
      "[102]\tvalid_0's auc: 0.634301\n",
      "[103]\tvalid_0's auc: 0.634313\n",
      "[104]\tvalid_0's auc: 0.634366\n",
      "[105]\tvalid_0's auc: 0.634497\n",
      "[106]\tvalid_0's auc: 0.634442\n",
      "[107]\tvalid_0's auc: 0.634487\n",
      "[108]\tvalid_0's auc: 0.634578\n",
      "[109]\tvalid_0's auc: 0.634676\n",
      "[110]\tvalid_0's auc: 0.63479\n",
      "[111]\tvalid_0's auc: 0.634846\n",
      "[112]\tvalid_0's auc: 0.634918\n",
      "[113]\tvalid_0's auc: 0.63501\n",
      "[114]\tvalid_0's auc: 0.634965\n",
      "[115]\tvalid_0's auc: 0.635029\n",
      "[116]\tvalid_0's auc: 0.635077\n",
      "[117]\tvalid_0's auc: 0.635075\n",
      "[118]\tvalid_0's auc: 0.6352\n",
      "[119]\tvalid_0's auc: 0.635215\n",
      "[120]\tvalid_0's auc: 0.635231\n",
      "[121]\tvalid_0's auc: 0.635276\n",
      "[122]\tvalid_0's auc: 0.635268\n",
      "[123]\tvalid_0's auc: 0.635221\n",
      "[124]\tvalid_0's auc: 0.635178\n",
      "[125]\tvalid_0's auc: 0.635221\n",
      "[126]\tvalid_0's auc: 0.635288\n",
      "[127]\tvalid_0's auc: 0.635345\n",
      "[128]\tvalid_0's auc: 0.635348\n",
      "[129]\tvalid_0's auc: 0.635414\n",
      "[130]\tvalid_0's auc: 0.635418\n",
      "[131]\tvalid_0's auc: 0.635352\n",
      "[132]\tvalid_0's auc: 0.635402\n",
      "[133]\tvalid_0's auc: 0.635497\n",
      "[134]\tvalid_0's auc: 0.635545\n",
      "[135]\tvalid_0's auc: 0.63565\n",
      "[136]\tvalid_0's auc: 0.635622\n",
      "[137]\tvalid_0's auc: 0.635664\n",
      "[138]\tvalid_0's auc: 0.635781\n",
      "[139]\tvalid_0's auc: 0.635735\n",
      "[140]\tvalid_0's auc: 0.635719\n",
      "[141]\tvalid_0's auc: 0.635815\n",
      "[142]\tvalid_0's auc: 0.635799\n",
      "[143]\tvalid_0's auc: 0.63583\n",
      "[144]\tvalid_0's auc: 0.635898\n",
      "[145]\tvalid_0's auc: 0.635924\n",
      "[146]\tvalid_0's auc: 0.635885\n",
      "[147]\tvalid_0's auc: 0.635919\n",
      "[148]\tvalid_0's auc: 0.63598\n",
      "[149]\tvalid_0's auc: 0.636035\n",
      "[150]\tvalid_0's auc: 0.636087\n",
      "[151]\tvalid_0's auc: 0.636139\n",
      "[152]\tvalid_0's auc: 0.63617\n",
      "[153]\tvalid_0's auc: 0.636128\n",
      "[154]\tvalid_0's auc: 0.636096\n",
      "[155]\tvalid_0's auc: 0.636206\n",
      "[156]\tvalid_0's auc: 0.636259\n",
      "[157]\tvalid_0's auc: 0.636289\n",
      "[158]\tvalid_0's auc: 0.636283\n",
      "[159]\tvalid_0's auc: 0.636287\n",
      "[160]\tvalid_0's auc: 0.636293\n",
      "[161]\tvalid_0's auc: 0.636324\n",
      "[162]\tvalid_0's auc: 0.63633\n",
      "[163]\tvalid_0's auc: 0.636367\n",
      "[164]\tvalid_0's auc: 0.636438\n",
      "[165]\tvalid_0's auc: 0.636483\n",
      "[166]\tvalid_0's auc: 0.636577\n",
      "[167]\tvalid_0's auc: 0.636645\n",
      "[168]\tvalid_0's auc: 0.63659\n",
      "[169]\tvalid_0's auc: 0.636595\n",
      "[170]\tvalid_0's auc: 0.636672\n",
      "[171]\tvalid_0's auc: 0.636719\n",
      "[172]\tvalid_0's auc: 0.636755\n",
      "[173]\tvalid_0's auc: 0.636833\n",
      "[174]\tvalid_0's auc: 0.636908\n",
      "[175]\tvalid_0's auc: 0.636929\n",
      "[176]\tvalid_0's auc: 0.636928\n",
      "[177]\tvalid_0's auc: 0.636962\n",
      "[178]\tvalid_0's auc: 0.636969\n",
      "[179]\tvalid_0's auc: 0.636995\n",
      "[180]\tvalid_0's auc: 0.637059\n",
      "[181]\tvalid_0's auc: 0.637089\n",
      "[182]\tvalid_0's auc: 0.637085\n",
      "[183]\tvalid_0's auc: 0.637121\n",
      "[184]\tvalid_0's auc: 0.637131\n",
      "[185]\tvalid_0's auc: 0.637133\n",
      "[186]\tvalid_0's auc: 0.637144\n",
      "[187]\tvalid_0's auc: 0.637189\n",
      "[188]\tvalid_0's auc: 0.637173\n",
      "[189]\tvalid_0's auc: 0.63719\n",
      "[190]\tvalid_0's auc: 0.637205\n",
      "[191]\tvalid_0's auc: 0.637131\n",
      "[192]\tvalid_0's auc: 0.637159\n",
      "[193]\tvalid_0's auc: 0.637185\n",
      "[194]\tvalid_0's auc: 0.63719\n",
      "[195]\tvalid_0's auc: 0.637224\n",
      "[196]\tvalid_0's auc: 0.637219\n",
      "[197]\tvalid_0's auc: 0.637193\n",
      "[198]\tvalid_0's auc: 0.637297\n",
      "[199]\tvalid_0's auc: 0.637329\n",
      "[200]\tvalid_0's auc: 0.6373\n",
      "[201]\tvalid_0's auc: 0.637257\n",
      "[202]\tvalid_0's auc: 0.637253\n",
      "[203]\tvalid_0's auc: 0.637261\n",
      "[204]\tvalid_0's auc: 0.637252\n",
      "[205]\tvalid_0's auc: 0.637273\n",
      "[206]\tvalid_0's auc: 0.637297\n",
      "[207]\tvalid_0's auc: 0.637345\n",
      "[208]\tvalid_0's auc: 0.637401\n",
      "[209]\tvalid_0's auc: 0.637456\n",
      "[210]\tvalid_0's auc: 0.637392\n",
      "[211]\tvalid_0's auc: 0.637373\n",
      "[212]\tvalid_0's auc: 0.63741\n",
      "[213]\tvalid_0's auc: 0.637459\n",
      "[214]\tvalid_0's auc: 0.637496\n",
      "[215]\tvalid_0's auc: 0.637539\n",
      "[216]\tvalid_0's auc: 0.637546\n",
      "[217]\tvalid_0's auc: 0.637535\n",
      "[218]\tvalid_0's auc: 0.637511\n",
      "[219]\tvalid_0's auc: 0.6375\n",
      "[220]\tvalid_0's auc: 0.637502\n",
      "[221]\tvalid_0's auc: 0.637493\n",
      "[222]\tvalid_0's auc: 0.637431\n",
      "[223]\tvalid_0's auc: 0.637413\n",
      "[224]\tvalid_0's auc: 0.637421\n",
      "[225]\tvalid_0's auc: 0.637368\n",
      "[226]\tvalid_0's auc: 0.637374\n",
      "[227]\tvalid_0's auc: 0.637374\n",
      "[228]\tvalid_0's auc: 0.637413\n",
      "[229]\tvalid_0's auc: 0.637429\n",
      "[230]\tvalid_0's auc: 0.637437\n",
      "[231]\tvalid_0's auc: 0.637488\n",
      "[232]\tvalid_0's auc: 0.637531\n",
      "[233]\tvalid_0's auc: 0.637529\n",
      "[234]\tvalid_0's auc: 0.637567\n",
      "[235]\tvalid_0's auc: 0.637599\n",
      "[236]\tvalid_0's auc: 0.637624\n",
      "[237]\tvalid_0's auc: 0.637659\n",
      "[238]\tvalid_0's auc: 0.637586\n",
      "[239]\tvalid_0's auc: 0.637656\n",
      "[240]\tvalid_0's auc: 0.637684\n",
      "[241]\tvalid_0's auc: 0.637682\n",
      "[242]\tvalid_0's auc: 0.637751\n",
      "[243]\tvalid_0's auc: 0.637722\n",
      "[244]\tvalid_0's auc: 0.637714\n",
      "[245]\tvalid_0's auc: 0.637647\n",
      "[246]\tvalid_0's auc: 0.637679\n",
      "[247]\tvalid_0's auc: 0.637679\n",
      "[248]\tvalid_0's auc: 0.637735\n",
      "[249]\tvalid_0's auc: 0.6377\n",
      "[250]\tvalid_0's auc: 0.637738\n",
      "[251]\tvalid_0's auc: 0.637708\n",
      "[252]\tvalid_0's auc: 0.637688\n",
      "[253]\tvalid_0's auc: 0.637725\n",
      "[254]\tvalid_0's auc: 0.637697\n",
      "[255]\tvalid_0's auc: 0.637689\n",
      "[256]\tvalid_0's auc: 0.637714\n",
      "[257]\tvalid_0's auc: 0.637688\n",
      "[258]\tvalid_0's auc: 0.637732\n",
      "[259]\tvalid_0's auc: 0.637703\n",
      "[260]\tvalid_0's auc: 0.63775\n",
      "[261]\tvalid_0's auc: 0.637715\n",
      "[262]\tvalid_0's auc: 0.637711\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's auc: 0.637751\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 9\n",
      "\n",
      "\n",
      "[2021-03-08T16:23:08.320367] The experiment completed successfully. Finalizing run...\n",
      "[2021-03-08T16:23:08.320402] Start FinalizingInRunHistory\n",
      "[2021-03-08T16:23:08.321149] Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 1.1708548069000244 seconds\n",
      "[2021-03-08T16:23:14.387751] Finished context manager injector.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: driver-training_1615220307_73384b5a\n",
      "Web View: https://ml.azure.com/experiments/driver-training/runs/driver-training_1615220307_73384b5a?wsid=/subscriptions/52061d21-01dd-4f9e-aca9-60fff4d67ee2/resourcegroups/MLOpsWorkshop/workspaces/mlops\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'driver-training_1615220307_73384b5a',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-03-08T16:22:42.830632Z',\n",
       " 'endTimeUtc': '2021-03-08T16:23:16.956994Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '96d17a11-7f8e-4bf6-aa8f-faa6a24c9355'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'driver_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'Experiment driver-training Environment',\n",
       "   'version': 'Autosave_2021-03-08T16:18:33Z_e1a68295',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn',\n",
       "      'lightgbm'],\n",
       "     'name': 'azureml_06c16b148b04e8226cfe58e6ee379ca1'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': None, 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mlops3730696013.blob.core.windows.net/azureml/ExperimentRun/dcid.driver-training_1615220307_73384b5a/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=ZK6vYlIPeXyD1wuFWl%2Fdn8%2F02efCbj168jelX86q5%2BI%3D&st=2021-03-08T16%3A14%3A11Z&se=2021-03-09T00%3A24%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mlops3730696013.blob.core.windows.net/azureml/ExperimentRun/dcid.driver-training_1615220307_73384b5a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=%2B%2BkSGP1JiELhOfelTb1VXmobsXVh%2FjZzqdPrguv9yOU%3D&st=2021-03-08T16%3A14%3A12Z&se=2021-03-09T00%3A24%3A12Z&sp=r',\n",
       "  'logs/azureml/9_azureml.log': 'https://mlops3730696013.blob.core.windows.net/azureml/ExperimentRun/dcid.driver-training_1615220307_73384b5a/logs/azureml/9_azureml.log?sv=2019-02-02&sr=b&sig=3WUlGo4ZrrDYsbRgLYSOLkGPpEuE5YiKoUfJT3ybtRk%3D&st=2021-03-08T16%3A13%3A11Z&se=2021-03-09T00%3A23%3A11Z&sp=r'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                      entry_script='driver_training.py',\n",
    "                      compute_target='local',  # we will use a remote training compute instance later\n",
    "                      conda_packages=['scikit-learn', 'lightgbm']\n",
    "                      )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'driver-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "run = experiment.submit(config=estimator)\n",
    "run.wait_for_completion(show_output=True)\n",
    "\n",
    "# while this cell executes we can see the progress in the AMLS portal.  \n",
    "# The output below will also give you a link for progress monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate 0.02\n",
      "boosting_type gbdt\n",
      "objective binary\n",
      "metric auc\n",
      "sub_feature 0.7\n",
      "num_leaves 60\n",
      "min_data 100\n",
      "min_hessian 1\n",
      "verbose 0\n",
      "auc 0.6377511613946426\n"
     ]
    }
   ],
   "source": [
    "# Print the resulting metrics by retrieving them from \n",
    "metrics = run.get_metrics()\n",
    "for k, v in metrics.items():\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='mlops', subscription_id='52061d21-01dd-4f9e-aca9-60fff4d67ee2', resource_group='MLOpsWorkshop'), name=driver_model.pkl, id=driver_model.pkl:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the model\n",
    "# note that the model is not in your filesystem here, it will be in the experiment \n",
    "# under \"Outputs+logs\".  Go verify that now.  \n",
    "run.register_model(model_path='outputs/driver_model.pkl', model_name='driver_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
