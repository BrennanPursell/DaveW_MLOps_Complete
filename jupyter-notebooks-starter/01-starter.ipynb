{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Starter Notebook\n",
        "This is a starter notebook with just the AMLS scaffolding.  You supply your data and code and generate a model.  "
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "To begin, you will need to provide the following information about your Azure Subscription.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "#Provide the Subscription ID of your existing Azure subscription.  This is merely an example\n",
        "subscription_id = \"52061d21-01dd-4f9e-aca9-60fff4d67ee2\" \n",
        "\n",
        "#Provide values for the existing Resource Group \n",
        "resource_group = \"MLOpsWorkshop\" # \n",
        "\n",
        "#Provide the Workspace Name and Azure Region of the Azure Machine Learning Workspace\n",
        "workspace_name = \"mlops\" # <- replace XXXXX with your unique identifier\n",
        "workspace_region = \"eastus\" # <- region of your Quick-Starts resource group"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "experiment_name = 'starter'\n",
        "project_folder = './starter'\n",
        "deployment_folder = './starter-deploy'\n",
        "\n",
        "# this is the name of the AML Compute cluster\n",
        "cluster_name = \"gpucluster\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Create the Azure Machine Learning resources"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The Azure Machine Learning SDK provides a comprehensive set of a capabilities that you can use directly within a notebook including:\n",
        "- Creating a **Workspace** that acts as the root object to organize all artifacts and resources used by Azure Machine Learning.\n",
        "- Creating **Experiments** in your Workspace that capture versions of the trained model along with any desired model performance telemetry. Each time you train a model and evaluate its results, you can capture that run (model and telemetry) within an Experiment.\n",
        "- Creating **Compute** resources that can be used to scale out model training, so that while your notebook may be running in a lightweight container in Azure Notebooks, your model training can actually occur on a powerful cluster that can provide large amounts of memory, CPU or GPU. \n",
        "- Using **Automated Machine Learning (AutoML)** to automatically train multiple versions of a model using a mix of different ways to prepare the data and different algorithms and hyperparameters (algorithm settings) in search of the model that performs best according to a performance metric that you specify.\n",
        "- Packaging a Docker **Image** that contains everything your trained model needs for scoring (prediction) in order to run as a web service.\n",
        "- Deploying your Image to either Azure Kubernetes or Azure Container Instances, effectively hosting the **Web Service**.\n",
        "\n",
        "In Azure Notebooks, all of the libraries needed for Azure Machine Learning are pre-installed. To use them, you just need to import them. Run the following cell to do so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "-packages (from matplotlib) (2.8.1)\nRequirement already satisfied: six in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: azureml in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (0.2.7)\nRequirement already satisfied: pandas in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml) (1.1.0)\nRequirement already satisfied: requests in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml) (2.24.0)\nRequirement already satisfied: python-dateutil in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml) (2.8.1)\nRequirement already satisfied: numpy>=1.15.4 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from pandas->azureml) (1.19.1)\nRequirement already satisfied: pytz>=2017.2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from pandas->azureml) (2020.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests->azureml) (1.25.10)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests->azureml) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests->azureml) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests->azureml) (2020.6.20)\nRequirement already satisfied: six>=1.5 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from python-dateutil->azureml) (1.15.0)\nWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the 'c:\\python37_64\\python.exe -m pip install --upgrade pip' command.\nDefaulting to user installation because normal site-packages is not writeableWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the 'c:\\python37_64\\python.exe -m pip install --upgrade pip' command.\n\nRequirement already satisfied: azureml-core in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (1.12.0.post1)\nRequirement already satisfied: azure-common>=1.1.12 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (1.1.25)\nRequirement already satisfied: docker in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (4.3.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (2.8.1)\nRequirement already satisfied: SecretStorage in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (3.1.2)\nRequirement already satisfied: PyJWT in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (1.7.1)\nRequirement already satisfied: pathspec in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.8.0)\nRequirement already satisfied: msrest>=0.5.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.6.18)\nRequirement already satisfied: urllib3>=1.23 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (1.25.10)\nRequirement already satisfied: pytz in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (2020.1)\nRequirement already satisfied: ndg-httpsclient in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.5.1)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (3.0)\nRequirement already satisfied: azure-mgmt-keyvault>=0.40.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (2.2.0)\nRequirement already satisfied: pyopenssl in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (19.1.0)\nRequirement already satisfied: requests>=2.19.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (2.24.0)\nRequirement already satisfied: jsonpickle in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (1.4.1)\nRequirement already satisfied: azure-mgmt-authorization>=0.40.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.61.0)\nRequirement already satisfied: azure-mgmt-resource>=1.2.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (10.2.0)\nRequirement already satisfied: ruamel.yaml>=0.15.35 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.16.10)\nRequirement already satisfied: backports.tempfile in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (1.0)\nRequirement already satisfied: adal>=1.2.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (1.2.4)\nRequirement already satisfied: contextlib2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.6.0.post1)\nRequirement already satisfied: jmespath in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.10.0)\nRequirement already satisfied: azure-graphrbac>=0.40.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.61.1)\nRequirement already satisfied: msrestazure>=0.4.33 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (0.6.4)\nRequirement already satisfied: azure-mgmt-storage>=1.5.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (11.1.0)\nRequirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core) (2.8.0)\nRequirement already satisfied: pywin32==227; sys_platform == \"win32\" in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from docker->azureml-core) (227)\nRequirement already satisfied: six>=1.4.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from docker->azureml-core) (1.15.0)\nRequirement already satisfied: websocket-client>=0.32.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from docker->azureml-core) (0.57.0)\nRequirement already satisfied: jeepney>=0.4.2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from SecretStorage->azureml-core) (0.4.3)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from msrest>=0.5.1->azureml-core) (2020.6.20)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from msrest>=0.5.1->azureml-core) (1.3.0)\nRequirement already satisfied: isodate>=0.6.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from msrest>=0.5.1->azureml-core) (0.6.0)\nRequirement already satisfied: pyasn1>=0.1.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from ndg-httpsclient->azureml-core) (0.4.8)\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core) (1.14.2)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.1->azureml-core) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.1->azureml-core) (2.10)\nRequirement already satisfied: importlib-metadata in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from jsonpickle->azureml-core) (1.7.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from ruamel.yaml>=0.15.35->azureml-core) (0.2.0)\nRequirement already satisfied: backports.weakref in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from backports.tempfile->azureml-core) (1.0.post1)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core) (3.1.0)\nRequirement already satisfied: pycparser in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core) (2.20)\nRequirement already satisfied: zipp>=0.5 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->jsonpickle->azureml-core) (3.1.0)\nDefaulting to user installation because normal site-packages is not writeable\nCollecting azureml-sdk\n  WARNING: The script distro.exe is installed in 'C:\\Users\\dave\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n  WARNING: The script azmldprep.exe is installed in 'C:\\Users\\dave\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n  WARNING: The script plasma_store.exe is installed in 'C:\\Users\\dave\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\nWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the 'c:\\python37_64\\python.exe -m pip install --upgrade pip' command.\n  Downloading azureml_sdk-1.12.0-py3-none-any.whl (4.4 kB)\nCollecting azureml-pipeline~=1.12.0\n  Downloading azureml_pipeline-1.12.0-py3-none-any.whl (3.7 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.12.0\n  Downloading azureml_dataset_runtime-1.12.0-py3-none-any.whl (3.2 kB)\nRequirement already satisfied: azureml-core~=1.12.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-sdk) (1.12.0.post1)\nCollecting azureml-train~=1.12.0\n  Downloading azureml_train-1.12.0-py3-none-any.whl (3.2 kB)\nCollecting azureml-train-automl-client~=1.12.0\n  Downloading azureml_train_automl_client-1.12.0-py3-none-any.whl (98 kB)\nCollecting azureml-pipeline-core~=1.12.0\n  Downloading azureml_pipeline_core-1.12.0-py3-none-any.whl (300 kB)\nCollecting azureml-pipeline-steps~=1.12.0\n  Downloading azureml_pipeline_steps-1.12.0-py3-none-any.whl (59 kB)\nCollecting azureml-dataprep<2.1.0a,>=2.0.1a\n  Downloading azureml_dataprep-2.0.7-py3-none-any.whl (28.2 MB)\nCollecting pyarrow<2.0.0,>=0.17.0\n  Downloading pyarrow-1.0.0-cp37-cp37m-win_amd64.whl (10.5 MB)\nCollecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\nRequirement already satisfied: ruamel.yaml>=0.15.35 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.16.10)\nRequirement already satisfied: requests>=2.19.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (2.24.0)\nRequirement already satisfied: msrestazure>=0.4.33 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.6.4)\nRequirement already satisfied: azure-mgmt-resource>=1.2.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (10.2.0)\nRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (3.0)\nRequirement already satisfied: azure-mgmt-authorization>=0.40.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.61.0)\nRequirement already satisfied: azure-mgmt-keyvault>=0.40.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (2.2.0)\nRequirement already satisfied: azure-common>=1.1.12 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (1.1.25)\nRequirement already satisfied: ndg-httpsclient in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.5.1)\nRequirement already satisfied: backports.tempfile in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (1.0)\nRequirement already satisfied: contextlib2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.6.0.post1)\nRequirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (2.8.1)\nRequirement already satisfied: msrest>=0.5.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.6.18)\nRequirement already satisfied: SecretStorage in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (3.1.2)\nRequirement already satisfied: urllib3>=1.23 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (1.25.10)\nRequirement already satisfied: azure-mgmt-storage>=1.5.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (11.1.0)\nRequirement already satisfied: pathspec in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.8.0)\nRequirement already satisfied: jsonpickle in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (1.4.1)\nRequirement already satisfied: docker in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (4.3.0)\nRequirement already satisfied: PyJWT in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (1.7.1)\nRequirement already satisfied: jmespath in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.10.0)\nRequirement already satisfied: pytz in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (2020.1)\nRequirement already satisfied: azure-graphrbac>=0.40.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (0.61.1)\nRequirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (2.8.0)\nRequirement already satisfied: pyopenssl in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (19.1.0)\nRequirement already satisfied: adal>=1.2.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from azureml-core~=1.12.0->azureml-sdk) (1.2.4)\nCollecting azureml-train-core~=1.12.0\n  Downloading azureml_train_core-1.12.0-py3-none-any.whl (8.6 MB)\nCollecting azureml-telemetry~=1.12.0\n  Downloading azureml_telemetry-1.12.0-py3-none-any.whl (29 kB)\nCollecting azureml-automl-core~=1.12.0\n  Downloading azureml_automl_core-1.12.0-py3-none-any.whl (158 kB)\nCollecting cloudpickle<2.0.0,>=1.1.0\n  Downloading cloudpickle-1.5.0-py3-none-any.whl (22 kB)\nCollecting azureml-dataprep-native<21.0.0,>=20.0.2\n  Downloading azureml_dataprep_native-20.0.2-cp37-cp37m-win_amd64.whl (7.8 MB)\nCollecting azure-identity<1.3.0,>=1.2.0\n  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\nCollecting dotnetcore2<3.0.0,>=2.1.14\n  Downloading dotnetcore2-2.1.14-py3-none-win_amd64.whl (30.7 MB)\nRequirement already satisfied: numpy>=1.14 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from pyarrow<2.0.0,>=0.17.0->azureml-dataset-runtime[fuse]~=1.12.0->azureml-sdk) (1.19.1)\nRequirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from ruamel.yaml>=0.15.35->azureml-core~=1.12.0->azureml-sdk) (0.2.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.1->azureml-core~=1.12.0->azureml-sdk) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.1->azureml-core~=1.12.0->azureml-sdk) (2020.6.20)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests>=2.19.1->azureml-core~=1.12.0->azureml-sdk) (2.10)\nRequirement already satisfied: six in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from msrestazure>=0.4.33->azureml-core~=1.12.0->azureml-sdk) (1.15.0)\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.12.0->azureml-sdk) (1.14.2)\nRequirement already satisfied: pyasn1>=0.1.1 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from ndg-httpsclient->azureml-core~=1.12.0->azureml-sdk) (0.4.8)\nRequirement already satisfied: backports.weakref in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from backports.tempfile->azureml-core~=1.12.0->azureml-sdk) (1.0.post1)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from msrest>=0.5.1->azureml-core~=1.12.0->azureml-sdk) (1.3.0)\nRequirement already satisfied: isodate>=0.6.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from msrest>=0.5.1->azureml-core~=1.12.0->azureml-sdk) (0.6.0)\nRequirement already satisfied: jeepney>=0.4.2 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from SecretStorage->azureml-core~=1.12.0->azureml-sdk) (0.4.3)\nRequirement already satisfied: importlib-metadata in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from jsonpickle->azureml-core~=1.12.0->azureml-sdk) (1.7.0)\nRequirement already satisfied: pywin32==227; sys_platform == \"win32\" in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from docker->azureml-core~=1.12.0->azureml-sdk) (227)\nRequirement already satisfied: websocket-client>=0.32.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from docker->azureml-core~=1.12.0->azureml-sdk) (0.57.0)\nCollecting azureml-train-restclients-hyperdrive~=1.12.0\n  Downloading azureml_train_restclients_hyperdrive-1.12.0-py3-none-any.whl (18 kB)\nCollecting applicationinsights\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\nCollecting msal-extensions~=0.1.3\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\nCollecting azure-core<2.0.0,>=1.0.0\n  Downloading azure_core-1.8.0-py2.py3-none-any.whl (121 kB)\nCollecting msal<2.0.0,>=1.0.0\n  Downloading msal-1.4.3-py2.py3-none-any.whl (49 kB)\nCollecting distro>=1.2.0\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\nRequirement already satisfied: pycparser in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.12.0->azureml-sdk) (2.20)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core~=1.12.0->azureml-sdk) (3.1.0)\nRequirement already satisfied: zipp>=0.5 in c:\\users\\dave\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata->jsonpickle->azureml-core~=1.12.0->azureml-sdk) (3.1.0)\nCollecting portalocker~=1.0"
        }
      ],
      "source": [
        "# this code block _might_ be needed if you run this outside azure, say on vscode\n",
        "!pip3 install matplotlib\n",
        "!pip3 install azureml\n",
        "!pip3 install azureml-core\n",
        "!pip3 install azureml-sdk"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.model import Model\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.core import Workspace"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Create and connect to an Azure Machine Learning Workspace\n",
        "Run the following cell to create a new Azure Machine Learning **Workspace** and save the configuration to disk (next to the Jupyter notebook). \n",
        "\n",
        "**Important Note**: You will be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace configuration succeeded`."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "tags": []
      },
      "cell_type": "code",
      "source": [
        "# By using the exist_ok param, if the worskpace already exists you get a reference to the existing workspace\n",
        "# allowing you to re-run this cell multiple times as desired (which is fairly common in notebooks).\n",
        "ws = Workspace.create(\n",
        "    name = workspace_name,\n",
        "    subscription_id = subscription_id,\n",
        "    resource_group = resource_group, \n",
        "    location = workspace_region,\n",
        "    exist_ok = True)\n",
        "\n",
        "ws.write_config()\n",
        "print('Workspace configuration succeeded')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING - Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\nWorkspace configuration succeeded\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Create AML Compute Cluster\n",
        "Now you are ready to create the GPU compute cluster. Run the following cell to create a new compute cluster (or retrieve the existing cluster if it already exists). The code below will create a *GPU based* cluster where each node in the cluster is of the size `Standard_NC12`, and the cluster is restricted to use 1 node. This will take couple of minutes to create."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "tags": []
      },
      "cell_type": "code",
      "source": [
        "### Create AML GPU based Compute Cluster\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC12',\n",
        "                                                           min_nodes=1, max_nodes=1)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# Use the 'status' property to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.status.serialize())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating a new compute target...\nCreating\nSucceeded...........................\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 1, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Resizing', 'allocationStateTransitionTime': '2020-08-19T16:02:56.797000+00:00', 'errors': None, 'creationTime': '2020-08-19T16:02:54.640024+00:00', 'modifiedTime': '2020-08-19T16:03:12.840261+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': ''}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC12'}\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Your code goes here"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Remote training using the Azure ML Compute\n",
        "Generally the training process is...you will deploy an Azure ML Compute cluster that will download the data and use a trainings script to train the model. In other words, all of the training will be performed remotely with respect to this notebook. \n"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# create project folder\n",
        "if not os.path.exists(project_folder):\n",
        "    os.makedirs(project_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Create the training script\n",
        "\n",
        "Eventually, you need to have something that looks like this...\n",
        "\n",
        "This may be a bit confusing.  \n",
        "\n",
        "The next cell does not execute the cell contents, rather it writes the cell to a file.  This becomes the training file that we can then package up and call directly from python later.  "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%writefile $project_folder/train.py\n",
        "\n",
        "glove_url = ('https://davewdemoblobs.blob.core.windows.net/mlops/glove.6B.100d.txt')\n",
        "data_url = ('https://davewdemoblobs.blob.core.windows.net/mlops/components.csv')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras import models \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "def download_glove():\n",
        "    print(\"Downloading GloVe embeddings...\")\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(glove_url, 'glove.6B.100d.txt')\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "download_glove()\n",
        "\n",
        "\n",
        "# Load the components labeled data\n",
        "print(\"Loading components data...\")\n",
        "components_df = pd.read_csv(data_url)\n",
        "components = components_df[\"text\"].tolist()\n",
        "labels = components_df[\"label\"].tolist()\n",
        "print(\"Loading components data completed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls /home/nbuser/library/jupyter-notebooks/dl\n",
        "!cat /home/nbuser/library/jupyter-notebooks/dl/train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%writefile --append $project_folder/train.py\n",
        "\n",
        "# split data 60% for trianing, 20% for validation, 20% for test\n",
        "print(\"Splitting data...\")\n",
        "train, validate, test = np.split(components_df.sample(frac=1), [int(.6*len(components_df)), int(.8*len(components_df))])\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(validate.shape)\n",
        "\n",
        "# use the Tokenizer from Keras to \"learn\" a vocabulary from the entire car components text\n",
        "print(\"Tokenizing data...\")\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 100                                           \n",
        "training_samples = 90000                                 \n",
        "validation_samples = 5000    \n",
        "max_words = 10000      \n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(components)\n",
        "sequences = tokenizer.texts_to_sequences(components)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])                     \n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]\n",
        "\n",
        "x_test = data[training_samples + validation_samples:]\n",
        "y_test = labels[training_samples + validation_samples:]\n",
        "print(\"Tokenizing data complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%writefile --append $project_folder/train.py\n",
        "\n",
        "# apply the vectors provided by GloVe to create a word embedding matrix\n",
        "print(\"Applying GloVe vectors...\")\n",
        "glove_dir =  './'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector    \n",
        "print(\"Applying GloVe vectors compelted.\")\n",
        "\n",
        "# use Keras to define the structure of the deep neural network   \n",
        "print(\"Creating model structure...\")\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# fix the weights for the first layer to those provided by the embedding matrix\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False\n",
        "print(\"Creating model structure completed.\")\n",
        "\n",
        "opt = optimizers.RMSprop(lr=0.1)\n",
        "\n",
        "print(\"Training model...\")\n",
        "model.compile(optimizer=opt,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=1, \n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "print(\"Training model completed.\")\n",
        "\n",
        "print(\"Saving model files...\")\n",
        "# create a ./outputs/model folder in the compute target\n",
        "# files saved in the \"./outputs\" folder are automatically uploaded into run history\n",
        "os.makedirs('./outputs/model', exist_ok=True)\n",
        "# save model\n",
        "model.save('./outputs/model/model.h5')\n",
        "print(\"model saved in ./outputs/model folder\")\n",
        "print(\"Saving model files completed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "!cat /home/nbuser/library/jupyter-notebooks/dl/train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Submit the training run"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The code pattern to submit a training run to Azure Machine Learning compute targets is always:\n",
        "\n",
        "- Create an experiment to run.\n",
        "- Submit the experiment.\n",
        "- Wait for the run to complete."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Create the experiment"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "experiment = Experiment(ws, experiment_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Submit the experiment"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "run = experiment.submit(keras_est)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Wait for the run to complete by executing the following cell. Note that this process will perform the following:\n",
        "- Build and deploy the container to Azure Machine Learning compute (~8 minutes)\n",
        "- Execute the training script (~2 minutes)\n",
        "\n",
        "If you change only the training script and re-submit, it will run faster the second time because the necessary container is already prepared so the time requried is just that for executing the training script.\n",
        "\n",
        "The experiment can be viewed in the Azure portal in the AMLS workspace.  It will probably initially be at Status = Preparing when you go look for it.  \n",
        "\n",
        "*Run the cell below and wait till the **Run Status** is **Completed** before proceeding ahead*"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(run).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Download the model files from the run"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "In the training script, the Keras model is saved into two files, model.json and model.h5, in the outputs/models folder on the GPU cluster AmlCompute node. Azure ML automatically uploaded anything written in the ./outputs folder into run history file store. Subsequently, we can use the run object to download the model files. They are under the the outputs/model folder in the run history file store, and are downloaded into a local folder named model."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# create a model folder in the current directory\n",
        "os.makedirs('./model', exist_ok=True)\n",
        "\n",
        "for f in run.get_file_names():\n",
        "    if f.startswith('outputs/model'):\n",
        "        output_file_path = os.path.join('./model', f.split('/')[-1])\n",
        "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
        "        run.download_file(name=f, output_file_path=output_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Restore the model from model.h5 file"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('./model/model.h5')\n",
        "print(\"Model loaded from disk.\")\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model on test data"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "You can also evaluate how accurately the model performs against data it has not seen. Run the following cell to load the test data that was not used in either training or evaluating the model. "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Load the components labeled data\n",
        "components_df = pd.read_csv(data_url)\n",
        "components = components_df[\"text\"].tolist()\n",
        "labels = components_df[\"label\"].tolist()\n",
        "\n",
        "maxlen = 100                                           \n",
        "training_samples = 90000                                 \n",
        "validation_samples = 5000    \n",
        "max_words = 10000      \n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(components)\n",
        "sequences = tokenizer.texts_to_sequences(components)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])                     \n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_test = data[training_samples + validation_samples:]\n",
        "y_test = labels[training_samples + validation_samples:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Run the following cell to see the accuracy on the test set (it is the second number in the array displayed, on a scale from 0 to 1)."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "print('Model evaluation will print the following metrics: ', model.metrics_names)\n",
        "evaluation_metrics = model.evaluate(x_test, y_test)\n",
        "print(evaluation_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Log the evaluation metrics to the to the experiment **Run**.  This will be available for viewing/logging/analytics in the azure portal.  "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "run.log(model.metrics_names[0], evaluation_metrics[0], 'Model test data loss')\n",
        "run.log(model.metrics_names[1], evaluation_metrics[1], 'Model test data accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "**Save the run information to json file**"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "run_info = {}\n",
        "run_info[\"id\"] = run.id\n",
        "\n",
        "print(\"Saving run_info.json...\")\n",
        "os.makedirs('./outputs', exist_ok=True)\n",
        "run_info_filepath = os.path.join('./outputs', 'run_info.json')\n",
        "with open(run_info_filepath, \"w\") as f:\n",
        "    json.dump(run_info, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python_defaultSpec_1597852572715",
      "display_name": "Python 3.7.8 64-bit",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "name": "Deep Learning",
    "notebookId": 2340934485665719
  },
  "nbformat": 4,
  "nbformat_minor": 1
}